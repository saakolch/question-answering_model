{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6YP38pEkBxqL4byrT3bLg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saakolch/question-answering_model/blob/main/Q-A_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3uchh96xzPy"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do tokenize"
      ],
      "metadata": {
        "id": "zc4kTQQszI9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "checkpoints = 'distilbert-base-cased-distilled-squad'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoints)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(checkpoints)\n",
        "\n",
        "\n",
        "content = '''\n",
        "\n",
        "Грани правильного октаэдра раскрашены в белый и черный цвет. При этом любые две грани, имеющие общее ребро, покрашены в разные цвета.\n",
        "Докажите, что для любой точки внутри октаэдра сумма расстояний до плоскостей белых граней равна сумме расстояний до плоскостей черных граней\n",
        "\n",
        "'''\n",
        "\n",
        "question = 'Какая тема этой задачи?'\n",
        "\n",
        "inputs = tokenizer(question, content, return_tensors='pt')\n",
        "outputs = model(**inputs)"
      ],
      "metadata": {
        "id": "JgtHcy9yx_P6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "start_logits.shape, end_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYURT9DT1KK7",
        "outputId": "632cdf63-c96c-4836-9cdc-6576bc04e4ef"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 254]), torch.Size([1, 254]))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to equate a [CLS] and [SEP] to number (a large negative number) for preparing to process of softmax using"
      ],
      "metadata": {
        "id": "b2QLP02rFVFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sequence_ids = inputs.sequence_ids()\n",
        "mask = [i != 1 for i in sequence_ids]\n",
        "mask[0] = False\n",
        "mask = torch.tensor(mask)[None]\n",
        "\n",
        "start_logits[mask] = -10000\n",
        "end_logits[mask] = -10000"
      ],
      "metadata": {
        "id": "YiHR0qBJz7XE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_prob = torch.nn.functional.softmax(start_logits, dim=-1)[0]\n",
        "end_prob = torch.nn.functional.softmax(end_logits, dim=-1)[0]"
      ],
      "metadata": {
        "id": "lXIJdLSRFGor"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we know the NLP tasks and especially question-answering task is a code + probability of appearing of words, based on previous information. So we are going to do a simple math here. We want to predict the start of the entity and the end of one. Assuming we have independent events such us answer in the text with probability at the start and probability at the end, therefore we need to multiple each prob of start-end and take the argmax of all of them"
      ],
      "metadata": {
        "id": "A_p8xZJ1G7eD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = start_prob[:, None] * end_prob[None,:]\n",
        "scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8_KRgQCGYkT",
        "outputId": "ed8d8948-f359-4dfd-9948-115318b22bb2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([254, 254])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = torch.triu(scores)\n",
        "scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFQCY1kSLln8",
        "outputId": "e89dc8d5-837a-4a4e-b28a-a463a31a2369"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([254, 254])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_index = scores.argmax().item()\n",
        "start_index = max_index // scores.shape[1]\n",
        "end_index = max_index % scores.shape[1]\n",
        "scores[start_index, end_index]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axti7ya4LqZq",
        "outputId": "c05effcd-58a9-4643-bafa-dca49f8c2695"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3980, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KAjKdwyfMPsu"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}